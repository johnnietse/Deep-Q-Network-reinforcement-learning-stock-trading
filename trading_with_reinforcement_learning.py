# -*- coding: utf-8 -*-
"""Trading with Reinforcement Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aOzV_7PB7tfQUb9l6Y6xt9o476OKddzv
"""

!pip install gym yfinance ta

# Commented out IPython magic to ensure Python compatibility.
# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

import gym
import yfinance as yf
import ta   # ta documentation: https://technical-analysis-library-in-python.readthedocs.io/en/latest/
from tqdm import tqdm
import numpy as np
import pandas as pd
from itertools import accumulate
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline


sns.set_style("darkgrid")

tickers = "^GSPC"  #"^GSPC" S&P500
df = yf.download(tickers = tickers ,       # list of tickers
                  period = "2y",         # time period
                  interval = "1h",       # trading interval
                  ignore_tz = True,      # ignore timezone when aligning data from different exchanges?
                  prepost = False)       # download pre/post market hours data?
print("shape of dataset: ",df.shape)
df.head()

split_line = int(np.round(len(df)* 0.1)) # use 10% of data for testing

# # Get min and max of 'Adj Close'
# adj_close_min = df['Close'].min()
# adj_close_max = df['Close'].max()

# # Set the background color
# sns.set_style(rc = {'axes.facecolor': 'lightsteelblue'})
# plt.figure(figsize=(12,4))

# # Create line plot
# sns.lineplot(data=df["Close"],label = "Adjusted Close Price")
# plt.xticks(rotation=45)
# plt.title(tickers)

# # single vline with full ymin and ymax
# plt.vlines(x=df.index[-split_line], ymin=adj_close_min, ymax=adj_close_max, colors='green', ls=':', lw=2, label='Train-Test Split Point')

# plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')
# plt.show()



# Get min and max of 'Adj Close'
adj_close_min = df['Close'].min()
adj_close_max = df['Close'].max()

# Set the background color
sns.set_style(rc={'axes.facecolor': 'lightsteelblue'})
plt.figure(figsize=(12, 4))

# Create line plot - CORRECTED LABEL SYNTAX
sns.lineplot(data=df["Close"]).set(label="Adjusted Close Price")  # <-- Fix here
plt.xticks(rotation=45)
plt.title(tickers)

# Add vertical split line
plt.vlines(
    x=df.index[-split_line],
    ymin=adj_close_min,
    ymax=adj_close_max,
    colors='green',
    ls=':',
    lw=2,
    label='Train-Test Split Point'
)

plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')
plt.show()

# df['EMA7'] = ta.trend.EMAIndicator(close= df['Close'], window= 7, fillna= False).ema_indicator()
# df['EMA14'] = ta.trend.EMAIndicator(close= df['Close'], window= 14, fillna= False).ema_indicator()
# df['EMA50'] = ta.trend.EMAIndicator(close= df['Close'], window= 50, fillna= False).ema_indicator()
# df['EMA200'] = ta.trend.EMAIndicator(close= df['Close'], window= 50, fillna= False).ema_indicator()
# Ensure 'Close' is a 1D Series
# df['Close'] = df['Close'].squeeze()

# # Calculate EMAs
# df['EMA7'] = ta.trend.EMAIndicator(close=df['Close'], window=7, fillna=False).ema_indicator()
# df['EMA14'] = ta.trend.EMAIndicator(close=df['Close'], window=14, fillna=False).ema_indicator()
# df['EMA50'] = ta.trend.EMAIndicator(close=df['Close'], window=50, fillna=False).ema_indicator()
# df['EMA200'] = ta.trend.EMAIndicator(close=df['Close'], window=200, fillna=False).ema_indicator()

# # Step 1: Convert 'Close' to a 1D Series
# df['Close'] = df['Close'].iloc[:, 0]  # Or use .values.ravel() approach

from ta.trend import EMAIndicator

close_series = pd.Series(df['Close'].values.squeeze(), index=df.index)

# Calculate EMAs with corrected 1D Series
df['EMA7'] = EMAIndicator(close=close_series, window=7, fillna=False).ema_indicator()
df['EMA14'] = EMAIndicator(close=close_series, window=14, fillna=False).ema_indicator()
df['EMA50'] = EMAIndicator(close=close_series, window=50, fillna=False).ema_indicator()
df['EMA200'] = EMAIndicator(close=close_series, window=50, fillna=False).ema_indicator()  # Fix window=200

# # Set the background color
# sns.set_style(rc = {'axes.facecolor': 'lightsteelblue'})
# plt.figure(figsize=(12,4))

# # Create line plot
# sns.lineplot(data=df["Close"],label = "Adjusted Close Price")
# sns.lineplot(data=df["EMA7"],label = "EMA7")
# sns.lineplot(data=df["EMA14"],label = "EMA14")
# sns.lineplot(data=df["EMA50"],label = "EMA50")
# sns.lineplot(data=df["EMA200"],label = "EMA200")


# plt.xticks(rotation=45)
# plt.title(tickers)


# Set the background color
sns.set_style(rc={'axes.facecolor': 'lightsteelblue'})
plt.figure(figsize=(12, 6))

# Use matplotlib's plot function instead of seaborn.lineplot for full control
plt.plot(df.index, df["Close"], label="Adjusted Close Price")
plt.plot(df.index, df["EMA7"], label="EMA7")
plt.plot(df.index, df["EMA14"], label="EMA14")
plt.plot(df.index, df["EMA50"], label="EMA50")
plt.plot(df.index, df["EMA200"], label="EMA200")

plt.xticks(rotation=45)
plt.title(tickers)
plt.legend()
plt.show()

# df['MACD_line'] =ta.trend.MACD(close= df['Adj Close'], window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd()
# df['MACD_signal'] =ta.trend.MACD(close= df['Adj Close'], window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd_signal()
# df['MACD_diff'] =ta.trend.MACD(close= df['Adj Close'], window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd_diff()


# Step 1: Check columns
print("Columns:", df.columns.tolist())

# Step 2: Ensure 'Close' is a proper 1D Series
# Create a 1D Series from the 'Close' column explicitly
close_series = pd.Series(df['Close'].values.squeeze(), index=df.index)


# Step 3: Calculate MACD using the explicit 1D Series
from ta.trend import MACD
# Pass the explicit 1D series to the MACD constructor
macd = MACD(close=close_series, window_slow=26, window_fast=12, window_sign=9, fillna=False)

# Assign the results directly - they should now be 1D Series
df['MACD_line'] = macd.macd()
df['MACD_signal'] = macd.macd_signal()
df['MACD_diff'] = macd.macd_diff()

# # Replace 'Close' with your actual column name (e.g., 'Adj_Close')
# df['MACD_line'] = ta.trend.MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False).macd()
# df['MACD_signal'] = ta.trend.MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False).macd_signal()
# df['MACD_diff'] = ta.trend.MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False).macd_diff()


# Import MACD
# from ta.trend import MACD # <--- Add this import


# # Step 1: Convert 'Close' to 1D Series
# df['Close'] = df['Close'].squeeze()  # or .iloc[:, 0]

# # Step 2: Calculate MACD
# macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False)
# df['MACD_line'] = macd.macd()
# df['MACD_signal'] = macd.macd_signal()
# df['MACD_diff'] = macd.macd_diff()

# print(df[['Close', 'MACD_line', 'MACD_signal', 'MACD_diff']].tail())



# # Step 1: Convert 'Close' to 1D Series
# close_values = df['Close'].values.ravel()
# df['Close'] = pd.Series(close_values, index=df.index)

# # Step 2: Calculate MACD
# from ta.trend import MACD
# macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False)
# df['MACD_line'] = macd.macd()
# df['MACD_signal'] = macd.macd_signal()
# df['MACD_diff'] = macd.macd_diff()



# # Step 1: Convert 'Close' to 1D Series
# close_values = df['Close'].values.ravel()
# df['Close'] = pd.Series(close_values, index=df.index)

# # Step 2: Calculate MACD
# from ta.trend import MACD
# macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False)

# # Explicitly squeeze the output to ensure it's 1D before assignment
# df['MACD_line'] = macd.macd().squeeze()
# df['MACD_signal'] = macd.macd_signal().squeeze()
# df['MACD_diff'] = macd.macd_diff().squeeze()


# # Step 1: Ensure 'Close' is 1D
# df['Close'] = pd.Series(df['Close'].values.ravel(), index=df.index)

# # Step 2: Calculate MACD with flattened outputs
# from ta.trend import MACD
# macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False)

# df['MACD_line'] = pd.Series(macd.macd().values.ravel(), index=df.index)
# df['MACD_signal'] = pd.Series(macd.macd_signal().values.ravel(), index=df.index)
# df['MACD_diff'] = pd.Series(macd.macd_diff().values.ravel(), index=df.index)



# # Step 1: Ensure 'Close' is 1D
# df['Close'] = df['Close'].squeeze()  # or .values.ravel()

# # Step 2: Calculate MACD and force 1D outputs
# from ta.trend import MACD
# macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False)

# # Flatten outputs
# df['MACD_line'] = macd.macd().values.ravel()
# df['MACD_signal'] = macd.macd_signal().values.ravel()
# df['MACD_diff'] = macd.macd_diff().values.ravel()


# # Step 1: Ensure 'Close' is 1D
# df['Close'] = df['Close'].squeeze()  # or .values.ravel()

# # Step 2: Calculate MACD
# from ta.trend import MACD
# macd = MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False)

# # Flatten outputs and assign to DataFrame columns
# # Explicitly convert the output to a pandas Series with the correct index
# # Use .squeeze() to ensure the output is 1D before creating the Series
# df['MACD_line'] = macd.macd().squeeze()
# df['MACD_signal'] = macd.macd_signal().squeeze()
# df['MACD_diff'] = macd.macd_diff().squeeze()

# Create a 1D Series from the 'Close' column explicitly
close_series = pd.Series(df['Close'].values.squeeze(), index=df.index)

df['RSI']=ta.momentum.RSIIndicator(close= close_series, window= 14, fillna= False).rsi()

# # adding Volumn indicator
# df['OBV']= ta.volume.OnBalanceVolumeIndicator(close= df['Adj Close'], volume= df['Volume'], fillna = False).on_balance_volume()
# df.head()

# df['OBV']= ta.volume.OnBalanceVolumeIndicator(close= df['Close'], volume= df['Volume'], fillna = False).on_balance_volume()
# df.head()

close_series = df['Close'].squeeze()
volume_series = df['Volume'].squeeze()


df['OBV']= ta.volume.OnBalanceVolumeIndicator(close= close_series, volume= volume_series, fillna = False).on_balance_volume()
df.head()

# df['BBH']=ta.volatility.BollingerBands(df['Adj Close'], window = 20, window_dev = 2, fillna = False).bollinger_hband_indicator()
# df['BBL']=ta.volatility.BollingerBands(df['Adj Close'], window = 20, window_dev = 2, fillna = False).bollinger_lband_indicator()
# df.head()

close_series = df['Close'].squeeze()


# Use the 'Close' column since 'Adj Close' is not available for 1h interval
df['BBH']=ta.volatility.BollingerBands(close_series, window = 20, window_dev = 2, fillna = False).bollinger_hband_indicator()
df['BBL']=ta.volatility.BollingerBands(close_series, window = 20, window_dev = 2, fillna = False).bollinger_lband_indicator()
df.head()

df.shape

df.columns

df=df.dropna()
# df = df.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume'],axis=1)
df = df.drop(columns=['Open', 'High', 'Low', 'Volume'],axis=1, errors='ignore')

df.head()

train_data = df.iloc[:-split_line,:]
test_data = df.iloc[-split_line:,:]
input_shape= train_data.shape[1]
print(input_shape)
print('Training data:',train_data.shape)
print('Testing data',test_data.shape)
print("Columns in train_data:", train_data.columns.tolist())

# import gym
# import numpy as np
# import pandas as pd # Import pandas


# class StockTradingEnv(gym.Env):
#     def __init__(self, data, initial_cash=10000, commission=0.000):
#         # Define the action space as a 2D vector representing the action type (buy or sell) and number of shares to trade
#         self.action_space = gym.spaces.MultiDiscrete([3, 10])  # [action, number of shares]

#         # Define the observation space as a X-D vector containing various indicators of the stock price
#         # self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(12,), dtype=np.float32)
#         self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(data.shape[1],), dtype=np.float32) #Dynamically set observation space shape


#         # Store the historical stock data, initial cash balance, and commission rate as instance variables
#         self.data = data
#         self.initial_cash = initial_cash
#         self.commission = commission
#         self.end_step = len(self.data) - 1

#         # Reset the environment to its initial state
#         self.reset()

#     def reset(self):
#         # Set the current step to 0 and reset the state variables
#         self.current_step = 0
#         self.profits = 0
#         self.shares_held = 0
#         self.cash = self.initial_cash
#         self.buy_price = 0
#         self.sell_price = 0
#         self.done = False

#         # Return the initial observation
#         return self._get_obs()

#     def step(self, action):
#         action_type, amount = action



#         if action_type == 0:
#             cost = self.data['Close'].iloc[self.current_step] * amount
#             if self.cash >= cost:
#                 self.cash -= cost
#                 self.shares_held += amount
#                 self.buy_price = self.data['Close'].iloc[self.current_step]
#         elif action_type == 1:
#             shares_sold = min(self.shares_held, amount)
#             revenue = self.data['Close'].iloc[self.current_step] * shares_sold
#             self.cash += revenue
#             self.profits += (self.data['Close'].iloc[self.current_step] - self.buy_price) * shares_sold
#             self.shares_held -= shares_sold
#             self.sell_price = self.data['Close'].iloc[self.current_step]

#         self.current_step += 1

#         # Calculate the total portfolio value
#         portfolio_value = self.cash + (self.shares_held * self.data['Close'].iloc[self.current_step])

#         # Calculate the reward based on the change in portfolio value at each stept
#         reward = portfolio_value - (self.cash + (self.shares_held * self.data['Close'].iloc[self.current_step - 1]))
#         done = (self.current_step == self.end_step)
#         return self._get_obs(), reward, done, {}



#     def _get_obs(self):
#     # Calculate the observation vector for the current step
#         obs = np.array([
#             self.data['Close'][self.current_step],
#             self.data['EMA7'][self.current_step],
#             self.data['EMA14'][self.current_step],
#             self.data['EMA50'][self.current_step],
#             self.data['EMA200'][self.current_step],
#             self.data['MACD_line'][self.current_step],
#             self.data['MACD_signal'][self.current_step],
#             self.data['MACD_diff'][self.current_step],
#             self.data['RSI'][self.current_step],
#             self.data['OBV'][self.current_step],
#             self.data['BBH'][self.current_step],
#             self.data['BBL'][self.current_step],
#         ])
#         # Return the observation vector
#         return obs

# ----------------------------------------------------------------------------------------------------------------------
# import gym
# import numpy as np
# import pandas as pd # Import pandas

# class StockTradingEnv(gym.Env):
#     def __init__(self, data, initial_cash=10000, commission=0.000):
#         # Define the action space as a 2D vector representing the action type (buy or sell) and number of shares to trade
#         self.action_space = gym.spaces.MultiDiscrete([3, 10])  # [action, number of shares]

#         # Define the observation space as a X-D vector containing various indicators of the stock price
#         # Ensure the shape matches the number of columns in the input data
#         self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(data.shape[1],), dtype=np.float32) #Dynamically set observation space shape

#         # Store the historical stock data, initial cash balance, and commission rate as instance variables
#         self.data = data
#         self.initial_cash = initial_cash
#         self.commission = commission
#         self.end_step = len(self.data) - 1

#         # Reset the environment to its initial state
#         self.reset()

#     def reset(self):
#         # Set the current step to 0 and reset the state variables
#         self.current_step = 0
#         self.profits = 0
#         self.shares_held = 0
#         self.cash = self.initial_cash
#         self.buy_price = 0
#         self.sell_price = 0
#         self.done = False

#         # Return the initial observation
#         return self._get_obs()

#     def step(self, action):
#         action_type, amount = action

#         # Access current price using iloc
#         current_price = self.data['Close'].iloc[self.current_step]

#         if action_type == 0: # Buy
#             cost = current_price * amount
#             if self.cash >= cost:
#                 self.cash -= cost
#                 self.shares_held += amount
#                 self.buy_price = current_price # Record buy price
#         elif action_type == 1: # Sell
#             shares_sold = min(self.shares_held, amount)
#             revenue = current_price * shares_sold
#             self.cash += revenue
#             # Calculate profit based on the average cost of held shares, not just the last buy price
#             # A more sophisticated approach would track individual buy lots
#             if self.shares_held > 0: # Prevent division by zero
#                  # Simple profit calculation based on the last buy price
#                  self.profits += (current_price - self.buy_price) * shares_sold
#             self.shares_held -= shares_sold
#             self.sell_price = current_price # Record sell price

#         self.current_step += 1

#         # Ensure the current step is within bounds before accessing data
#         if self.current_step > self.end_step:
#             self.current_step = self.end_step # Or handle end of episode differently

#         # Calculate the total portfolio value using the *next* step's closing price
#         # to reflect the value at the end of the current step's action
#         # Ensure next_price is accessed safely
#         next_price = self.data['Close'].iloc[self.current_step] if self.current_step <= self.end_step else current_price # Use current price if at end

#         portfolio_value = self.cash + (self.shares_held * next_price)

#         # Calculate the reward based on the change in portfolio value at each step
#         # Need to keep track of the portfolio value from the previous step
#         previous_portfolio_value = self.cash + (self.shares_held * self.data['Close'].iloc[self.current_step - 1]) # Use iloc for previous step

#         reward = portfolio_value - previous_portfolio_value
#         done = (self.current_step == self.end_step)

#         # Return the next observation, reward, done flag, and info dictionary
#         # Ensure next_state is generated from a valid step index
#         next_obs = self._get_obs() if self.current_step <= self.end_step else self._get_obs() # Return the last observation if done


#         return next_obs, reward, done, {}



#     def _get_obs(self):
#         # Calculate the observation vector for the current step
#         # Use .iloc to access rows by integer position
#         current_data_row = self.data.iloc[self.current_step]

#         obs = np.array([
#             current_data_row['Close'],
#             current_data_row['EMA7'],
#             current_data_row['EMA14'],
#             current_data_row['EMA50'],
#             current_data_row['EMA200'],
#             current_data_row['MACD_line'],
#             current_data_row['MACD_signal'],
#             current_data_row['MACD_diff'],
#             current_data_row['RSI'],
#             current_data_row['OBV'],
#             current_data_row['BBH'],
#             current_data_row['BBL'],
#         ])
#         # Return the observation vector
#         return obs

#------------------------------------------------------------------------------------------------------------------

# import gym
# import numpy as np
# import pandas as pd # Import pandas

# class StockTradingEnv(gym.Env):
#     def __init__(self, data, initial_cash=10000, commission=0.000):
#         # Define the action space as a 2D vector representing the action type (buy or sell) and number of shares to trade
#         self.action_space = gym.spaces.MultiDiscrete([3, 10])  # [action, number of shares]

#         # Define the observation space as a X-D vector containing various indicators of the stock price
#         # Ensure the shape matches the number of columns in the input data
#         self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(data.shape[1],), dtype=np.float32) #Dynamically set observation space shape

#         # Store the historical stock data, initial cash balance, and commission rate as instance variables
#         self.data = data
#         self.initial_cash = initial_cash
#         self.commission = commission
#         self.end_step = len(self.data) - 1

#         # Reset the environment to its initial state
#         self.reset()

#     def reset(self):
#         # Set the current step to 0 and reset the state variables
#         self.current_step = 0
#         self.profits = 0
#         self.shares_held = 0
#         self.cash = self.initial_cash
#         self.buy_price = 0
#         self.sell_price = 0
#         self.done = False

#         # Return the initial observation
#         return self._get_obs()

#     def step(self, action):
#         action_type, amount = action

#         # Access current price using iloc and extract the scalar value
#         current_price = self.data['Close'].iloc[self.current_step].item()

#         if action_type == 0: # Buy
#             cost = current_price * amount
#             if self.cash >= cost:
#                 self.cash -= cost
#                 self.shares_held += amount
#                 self.buy_price = current_price # Record buy price
#         elif action_type == 1: # Sell
#             shares_sold = min(self.shares_held, amount)
#             revenue = current_price * shares_sold
#             self.cash += revenue
#             # Calculate profit based on the average cost of held shares, not just the last buy price
#             # A more sophisticated approach would track individual buy lots
#             if self.shares_held > 0: # Prevent division by zero
#                  # Simple profit calculation based on the last buy price
#                  self.profits += (current_price - self.buy_price) * shares_sold
#             self.shares_held -= shares_sold
    #         self.sell_price = current_price # Record sell price

    #     self.current_step += 1

    #     # Ensure the current step is within bounds before accessing data
    #     if self.current_step > self.end_step:
    #         self.current_step = self.end_step # Or handle end of episode differently

    #     # Calculate the total portfolio value using the *next* step's closing price
    #     # to reflect the value at the end of the current step's action
    #     # Ensure next_price is accessed safely and is a scalar
    #     next_price = self.data['Close'].iloc[self.current_step].item() if self.current_step <= self.end_step else current_price # Use current price if at end

    #     portfolio_value = self.cash + (self.shares_held * next_price)

    #     # Calculate the reward based on the change in portfolio value at each step
    #     # Need to keep track of the portfolio value from the previous step
    #     # Ensure previous_price is accessed safely and is a scalar
    #     previous_price = self.data['Close'].iloc[self.current_step - 1].item() if self.current_step > 0 else current_price # Use current price if at start
    #     previous_portfolio_value = self.cash + (self.shares_held * previous_price) # Use iloc for previous step


    #     reward = portfolio_value - previous_portfolio_value
    #     done = (self.current_step == self.end_step)

    #     # Return the next observation, reward, done flag, and info dictionary
    #     # Ensure next_state is generated from a valid step index
    #     next_obs = self._get_obs() if self.current_step <= self.end_step else self._get_obs() # Return the last observation if done


    #     return next_obs, reward, done, {}



    # def _get_obs(self):
    #     # Calculate the observation vector for the current step
    #     # Use .iloc to access rows by integer position
    #     current_data_row = self.data.iloc[self.current_step]

    #     obs = np.array([
    #         current_data_row['Close'],
    #         current_data_row['EMA7'],
    #         current_data_row['EMA14'],
    #         current_data_row['EMA50'],
    #         current_data_row['EMA200'],
    #         current_data_row['MACD_line'],
    #         current_data_row['MACD_signal'],
    #         current_data_row['MACD_diff'],
    #         current_data_row['RSI'],
    #         current_data_row['OBV'],
    #         current_data_row['BBH'],
        #     current_data_row['BBL'],
        # ])
        # # Return the observation vector
        # return obs



import gym
import numpy as np
import pandas as pd # Import pandas

class StockTradingEnv(gym.Env):
    def __init__(self, data, initial_cash=10000, commission=0.000):
        # Define the action space as a 2D vector representing the action type (buy or sell) and number of shares to trade
        self.action_space = gym.spaces.MultiDiscrete([3, 10])  # [action, number of shares]

        # Define the observation space as a X-D vector containing various indicators of the stock price
        # Ensure the shape matches the number of columns in the input data
        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(data.shape[1],), dtype=np.float32) #Dynamically set observation space shape

        # Store the historical stock data, initial cash balance, and commission rate as instance variables
        self.data = data
        self.initial_cash = initial_cash
        self.commission = commission
        self.end_step = len(self.data) - 1

        # Reset the environment to its initial state
        self.reset()

    def reset(self):
        # Set the current step to 0 and reset the state variables
        self.current_step = 0
        self.profits = 0
        self.shares_held = 0
        self.cash = self.initial_cash
        self.buy_price = 0
        self.sell_price = 0
        self.done = False

        # Return the initial observation
        return self._get_obs()

    def step(self, action):
        action_type, amount = action

        # Access current price using iloc and extract the scalar value
        current_price = self.data['Close'].iloc[self.current_step].item()

        if action_type == 0: # Buy
            cost = current_price * amount
            if self.cash >= cost:
                self.cash -= cost
                self.shares_held += amount
                self.buy_price = current_price # Record buy price
        elif action_type == 1: # Sell
            shares_sold = min(self.shares_held, amount)
            revenue = current_price * shares_sold
            self.cash += revenue
            # Calculate profit based on the average cost of held shares, not just the last buy price
            # A more sophisticated approach would track individual buy lots
            if self.shares_held > 0: # Prevent division by zero
                 # Simple profit calculation based on the last buy price
                 self.profits += (current_price - self.buy_price) * shares_sold
            self.shares_held -= shares_sold
            self.sell_price = current_price # Record sell price

        self.current_step += 1

        # Ensure the current step is within bounds before accessing data
        if self.current_step > self.end_step:
            self.current_step = self.end_step # Or handle end of episode differently

        # Calculate the total portfolio value using the *next* step's closing price
        # to reflect the value at the end of the current step's action
        # Ensure next_price is accessed safely and is a scalar
        next_price = self.data['Close'].iloc[self.current_step].item() if self.current_step <= self.end_step else current_price # Use current price if at end

        portfolio_value = self.cash + (self.shares_held * next_price)

        # Calculate the reward based on the change in portfolio value at each step
        # Need to keep track of the portfolio value from the previous step
        # Ensure previous_price is accessed safely and is a scalar
        previous_price = self.data['Close'].iloc[self.current_step - 1].item() if self.current_step > 0 else current_price # Use current price if at start
        previous_portfolio_value = self.cash + (self.shares_held * previous_price) # Use iloc for previous step


        reward = portfolio_value - previous_portfolio_value
        done = (self.current_step == self.end_step)

        # Return the next observation, reward, done flag, and info dictionary
        # Ensure next_state is generated from a valid step index
        next_obs = self._get_obs() if self.current_step <= self.end_step else self._get_obs() # Return the last observation if done


        return next_obs, reward, done, {}



    def _get_obs(self):
        # Calculate the observation vector for the current step
        # Use .iloc to access rows by integer position
        current_data_row = self.data.iloc[self.current_step]

        obs = np.array([
            current_data_row['Close'],
            current_data_row['EMA7'],
            current_data_row['EMA14'],
            current_data_row['EMA50'],
            current_data_row['EMA200'],
            current_data_row['MACD_line'],
            current_data_row['MACD_signal'],
            current_data_row['MACD_diff'],
            current_data_row['RSI'],
            current_data_row['OBV'],
            current_data_row['BBH'],
            current_data_row['BBL'],
        ])
        # Return the observation vector
        return obs

import random
import numpy as np
from collections import deque
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD, Adam

class DQNAgent:
    def __init__(self, state_size, action_space,memory_size=3000):
        # Initialize instance variables
        self.state_size = state_size
        self.action_space = action_space
        self.action_size = action_space.nvec.prod()
        self.memory = deque(maxlen=memory_size)
        self.gamma = 0.95
        self.epsilon = 1.0
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = 0.01
        self.model = self._build_model()

    def _build_model(self):
        # Build the neural network model
        model = Sequential()
        model.add(Dense(64, input_dim=self.state_size))
        model.add(Dense(128, activation='relu'))
        model.add(Dense(256, activation='relu'))
        model.add(Dense(128, activation='relu'))
        model.add(Dense(self.action_size, activation='relu'))
        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))
        return model

    def remember(self, state, action, reward, next_state, done):
        # Store the experience in memory
        self.memory.append((state, action, reward, next_state, done))

    def act(self, state):
        # Choose an action using the epsilon-greedy strategy
        if np.random.rand() <= self.epsilon:
            return (random.randrange(self.action_space.nvec[0]), random.randrange(self.action_space.nvec[1]))
        act_values = self.model.predict(state)
        return np.unravel_index(np.argmax(act_values[0]), self.action_space.nvec)

    def replay(self, batch_size):
        # Train the model using random samples from memory
        minibatch = random.sample(self.memory, batch_size)
        for state, action, reward, next_state, done in minibatch:
            target = reward
            if not done:
                # Update target value for non-terminal states
                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])
            target_f = self.model.predict(state)

            # Convert the action tuple to a linear index
            action_idx = np.ravel_multi_index(action, self.action_space.nvec)

            # Update the target value for the chosen action
            target_f[0][action_idx] = target
            self.model.fit(state, target_f, epochs=1, verbose=0)

        # Decay the exploration rate if it's above the minimum threshold
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# Load the stock data
data = train_data[['Close', 'EMA7', 'EMA14', 'EMA50', 'EMA200', 'MACD_line', 'MACD_signal', 'MACD_diff', 'RSI', 'OBV', 'BBH', 'BBL']].copy()


# Create the environment
env = StockTradingEnv(data)
state_size = env.observation_space.shape[0]
action_size = env.action_space.nvec.prod()

# Create and train the agent
agent = DQNAgent(state_size, env.action_space)
episodes = 10
batch_size = 32

for e in tqdm(range(episodes)):
    state = env.reset()
    state = np.reshape(state, [1, state_size])
    total_reward = 0

    while True:
        action = agent.act(state)
        next_state, reward, done, _ = env.step(action)
        total_reward += reward
        next_state = np.reshape(next_state, [1, state_size])

        agent.remember(state, action, reward, next_state, done)
        state = next_state

        if done:
            # print(f'Episode: {e + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.2}')
            break

    if len(agent.memory) > batch_size:
        agent.replay(batch_size)

# import matplotlib.pyplot as plt

# # Load the test data
# test_data = test_data.iloc[:,:]

# # change this to 1 to get records of all transactions
# verbose = 0

# # Create the test environment
# test_env = StockTradingEnv(test_data, initial_cash=10000)

# # Test the agent
# state = test_env.reset()
# state = np.reshape(state, [1, state_size])
# total_reward = 0

# # Initialize lists to store the buy and sell prices and the corresponding time steps
# buy_prices = []
# buy_times = []
# sell_prices = []
# sell_times = []

# # Initialize the list to store portfolio values and add the initial portfolio value
# portfolio_values = [test_env.cash]

# while True:
#     action = agent.act(state)
#     next_state, reward, done, _ = test_env.step(action)

#     # Calculate the total portfolio value
#     portfolio_value = test_env.cash + (test_env.shares_held * test_env.data['Close'][test_env.current_step])
#     portfolio_values.append(portfolio_value)

#     # Print the action details
#     action_type, shares = action
#     if(verbose ==1):
#         if action_type == 0:
#             print(f"Buy {shares} shares at price {test_env.data['Close'][test_env.current_step]}")
#         elif action_type == 1:
#             print(f"Sell {shares} shares at price {test_env.data['Close'][test_env.current_step]}")

#         # Print available cash, number of shares held, and reward
#         print(f"Available cash: {test_env.cash}",f",Shares held: {test_env.shares_held}",f",Reward: {reward}")
#         print("------------------------------------------------")

#     total_reward += reward
#     next_state = np.reshape(next_state, [1, state_size])
#     state = next_state

#     # Check if a buy action was taken and record the price and time step
#     if action[0] == 0:
#         buy_prices.append(test_data['Close'][test_env.current_step])
#         buy_times.append(test_data.index[test_env.current_step])

#     # Check if a sell action was taken and record the price and time step
#     elif action[0] == 1:
#         sell_prices.append(test_data['Close'][test_env.current_step])
#         sell_times.append(test_data.index[test_env.current_step])

#     if done:
#         print(f'Test: Total Reward: {total_reward}')
#         break

# # Calculate the percentage change in the portfolio value
# portfolio_percentage_changes = [((value - portfolio_values[0]) / portfolio_values[0]) * 100 for value in portfolio_values]

# # Create the figure with two subplots
# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)

# # Plot the historical price data as a line chart on the first subplot
# ax1.plot(test_data.index, test_data['Close'])

# # Plot the buy and sell actions as red and blue dots, respectively, on the first subplot
# ax1.scatter(buy_times, buy_prices, color='b', marker='o', label='Buy')
# ax1.scatter(sell_times, sell_prices, color='r', marker='o', label='Sell')

# # Set the first subplot's title, x-label, and y-label
# ax1.set_title('Trading History')
# ax1.set_xlabel('Time')
# ax1.set_ylabel('Price')
# ax1.legend()

# # Plot the percentage change in the portfolio value on the second subplot
# # ax2.plot(test_data.index, portfolio_percentage_changes, color='g', linestyle='--', label='Portfolio % Change')


# # Add a point for the initial cash on the portfolio value plot
# # Create a time index for the initial portfolio value
# initial_time_index = test_data.index[0]

# # Plot the percentage change in the portfolio value on the second subplot
# # Include the initial portfolio value with its corresponding time index
# ax2.plot([initial_time_index] + list(test_data.index), portfolio_percentage_changes, color='g', linestyle='--', label='Portfolio % Change')



# # Set the second subplot's title, x-label, and y-label
# ax2.set_title('Portfolio Value Change')
# ax2.set_xlabel('Time')
# ax2.set_ylabel('% Change')
# ax2.legend()

# # Display the chart
# plt.show()


# import matplotlib.pyplot as plt
# import numpy as np # Import numpy
# import pandas as pd # Import pandas
# import gym # Import gym

# # Load the test data
# split_line = int(np.round(len(df)* 0.1)) # Redefine split_line if needed, or ensure it's available
# test_data = df.iloc[-split_line:,:] # Define test_data here

# # change this to 1 to get records of all transactions
# verbose = 0

# # Create the test environment
# test_env = StockTradingEnv(test_data, initial_cash=10000)

# # Test the agent
# state = test_env.reset()
# state = np.reshape(state, [1, state_size])
# total_reward = 0

# # Initialize lists to store the buy and sell prices and the corresponding time steps
# buy_prices = []
# buy_times = []
# sell_prices = []
# sell_times = []

# # Initialize the list to store portfolio values and add the initial portfolio value
# portfolio_values = [test_env.cash]

# # Keep track of the last observed price for calculating the final portfolio value
# last_price = None

# while True:
#     action = agent.act(state)
#     next_state, reward, done, _ = test_env.step(action)

#     # Update last_price with the price from the new state
#     last_price = next_state[0][0] # Assuming Close price is the first element in the observation

#     # Print the action details
#     action_type, shares = action
#     if(verbose ==1):
#         # Use the price from the current state before the step to report the transaction price
#         current_price_for_verbose = state[0][0]
#         if action_type == 0:
#             print(f"Buy {shares} shares at price {current_price_for_verbose}")
#         elif action_type == 1:
#             print(f"Sell {shares} shares at price {current_price_for_verbose}")

#         # Print available cash, number of shares held, and reward
#         print(f"Available cash: {test_env.cash}",f",Shares held: {test_env.shares_held}",f",Reward: {reward}")
#         print("------------------------------------------------")

#     total_reward += reward
#     next_state = np.reshape(next_state, [1, state_size])

#     # Check if a buy action was taken and record the price and time step
#     if action[0] == 0:
#         # Use the price from the state *before* the step and the index *before* the step increment
#         buy_prices.append(state[0][0])
#         # Need to ensure test_env.current_step - 1 is valid for indexing
#         if test_env.current_step - 1 >= 0:
#              buy_times.append(test_data.index[test_env.current_step - 1])


#     # Check if a sell action was taken and record the price and time step
#     elif action[0] == 1:
#         # Use the price from the state *before* the step and the index *before* the step increment
#         sell_prices.append(state[0][0])
#          # Need to ensure test_env.current_step - 1 is valid for indexing
#         if test_env.current_step - 1 >= 0:
#             sell_times.append(test_data.index[test_env.current_step - 1])

#     state = next_state

#     if done:
#         # Calculate the final portfolio value using the last observed price
#         final_portfolio_value = test_env.cash + (test_env.shares_held * last_price)
#         portfolio_values.append(final_portfolio_value)
#         print(f'Test: Total Reward: {total_reward}')
#         break
#     else:
#          # Append portfolio value at each step using the last observed price
#          portfolio_values.append(test_env.cash + (test_env.shares_held * last_price))


# # Calculate the percentage change in the portfolio value
# portfolio_percentage_changes = [((value - portfolio_values[0]) / portfolio_values[0]) * 100 for value in portfolio_values]

# # Create the figure with two subplots
# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)

# # Plot the historical price data as a line chart on the first subplot
# ax1.plot(test_data.index, test_data['Close'])

# # Plot the buy and sell actions as red and blue dots, respectively, on the first subplot
# ax1.scatter(buy_times, buy_prices, color='b', marker='o', label='Buy')
# ax1.scatter(sell_times, sell_prices, color='r', marker='o', label='Sell')

# # Set the first subplot's title, x-label, and y-label
# ax1.set_title('Trading History')
# ax1.set_xlabel('Time')
# ax1.set_ylabel('Price')
# ax1.legend()

# # Add a point for the initial cash on the portfolio value plot
# # Create a time index for the initial portfolio value
# initial_time_index = test_data.index[0]

# # Plot the percentage change in the portfolio value on the second subplot
# # Include the initial portfolio value with its corresponding time index
# ax2.plot([initial_time_index] + list(test_data.index), portfolio_percentage_changes, color='g', linestyle='--', label='Portfolio % Change')



# # Set the second subplot's title, x-label, and y-label
# ax2.set_title('Portfolio Value Change')
# ax2.set_xlabel('Time')
# ax2.set_ylabel('% Change')
# ax2.legend()

# # Display the chart
# plt.show()



import matplotlib.pyplot as plt
import numpy as np # Import numpy
import pandas as pd # Import pandas
import gym # Import gym

# Load the test data
# Ensure test_data is defined before use
# Assuming df is already loaded from previous cells
# The split_line and test_data definition is already done in a previous cell
# split_line = int(np.round(len(df)* 0.1)) # Redefine split_line if needed, or ensure it's available
# test_data = df.iloc[-split_line:,:] # Define test_data here


# change this to 1 to get records of all transactions
verbose = 0

# Assuming StockTradingEnv and DQNAgent classes are defined in previous cells
# Assuming state_size is defined from the training phase
# Create the test environment
test_env = StockTradingEnv(test_data, initial_cash=10000)

# Test the agent
state = test_env.reset()
state = np.reshape(state, [1, state_size])
total_reward = 0

# Initialize lists to store the buy and sell prices and the corresponding time steps
buy_prices = []
buy_times = []
sell_prices = []
sell_times = []

# Initialize the list to store portfolio values and add the initial portfolio value
portfolio_values = [test_env.cash]

# Keep track of the last observed price for calculating the final portfolio value
last_price = None

while True:
    action = agent.act(state)
    next_state, reward, done, _ = test_env.step(action)

    # Update last_price with the price from the new state
    # Ensure next_state is not None and has the expected shape
    if next_state is not None and next_state.shape[1] > 0:
         last_price = next_state[0][0] # Assuming Close price is the first element in the observation

    # Print the action details
    action_type, shares = action
    if(verbose ==1):
        # Use the price from the current state before the step to report the transaction price
        current_price_for_verbose = state[0][0]
        if action_type == 0:
            print(f"Buy {shares} shares at price {current_price_for_verbose}")
        elif action_type == 1:
            print(f"Sell {shares} shares at price {current_price_for_verbose}")

        # Print available cash, number of shares held, and reward
        print(f"Available cash: {test_env.cash}",f",Shares held: {test_env.shares_held}",f",Reward: {reward}")
        print("------------------------------------------------")

    total_reward += reward
    next_state = np.reshape(next_state, [1, state_size])

    # Check if a buy action was taken and record the price and time step
    if action[0] == 0:
        # Use the price from the state *before* the step and the index *before* the step increment
        buy_prices.append(state[0][0])
        # Need to ensure test_env.current_step - 1 is valid for indexing
        # The current_step is incremented *after* the action is taken in the step function
        # So, the price and index corresponding to the action taken is from the previous step
        if test_env.current_step -1 >= 0:
             buy_times.append(test_data.index[test_env.current_step -1])


    # Check if a sell action was taken and record the price and time step
    elif action[0] == 1:
        # Use the price from the state *before* the step and the index *before* the step increment
        sell_prices.append(state[0][0])
         # Need to ensure test_env.current_step - 1 is valid for indexing
        if test_env.current_step - 1 >= 0:
            sell_times.append(test_data.index[test_env.current_step - 1])

    state = next_state

    if done:
        # Calculate the final portfolio value using the last observed price
        # Ensure last_price is not None before using it
        if last_price is not None:
             final_portfolio_value = test_env.cash + (test_env.shares_held * last_price)
        else:
             # If last_price is None (e.g., if the loop finished immediately), use the current cash
             final_portfolio_value = test_env.cash
        portfolio_values.append(final_portfolio_value)
        print(f'Test: Total Reward: {total_reward}')
        break
    else:
         # Append portfolio value at each step using the last observed price
         # Ensure last_price is not None before using it
        if last_price is not None:
             portfolio_values.append(test_env.cash + (test_env.shares_held * last_price))
        else:
             # If last_price is None, append the current cash
             portfolio_values.append(test_env.cash)



# Calculate the percentage change in the portfolio value
# Ensure portfolio_values has at least two elements for the calculation
if len(portfolio_values) > 1:
    portfolio_percentage_changes = [((value - portfolio_values[0]) / portfolio_values[0]) * 100 if portfolio_values[0] != 0 else 0 for value in portfolio_values]
else:
    # Handle the case where no steps were taken
    portfolio_percentage_changes = [0]


# Create the figure with two subplots
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)

# Plot the historical price data as a line chart on the first subplot
ax1.plot(test_data.index, test_data['Close'])

# Plot the buy and sell actions as red and blue dots, respectively, on the first subplot
ax1.scatter(buy_times, buy_prices, color='b', marker='o', label='Buy')
ax1.scatter(sell_times, sell_prices, color='r', marker='o', label='Sell')

# Set the first subplot's title, x-label, and y-label
ax1.set_title('Trading History')
ax1.set_xlabel('Time')
ax1.set_ylabel('Price')
ax1.legend()

# Add a point for the initial cash on the portfolio value plot
# Create a time index for the initial portfolio value
initial_time_index = test_data.index[0]

# Plot the percentage change in the portfolio value on the second subplot
# Include the initial portfolio value with its corresponding time index
# Ensure the time index list matches the portfolio_percentage_changes list length
if len(portfolio_percentage_changes) > 0:
     ax2.plot([initial_time_index] + list(test_data.index[:len(portfolio_percentage_changes)-1]), portfolio_percentage_changes, color='g', linestyle='--', label='Portfolio % Change')


# Set the second subplot's title, x-label, and y-label
ax2.set_title('Portfolio Value Change')
ax2.set_xlabel('Time')
ax2.set_ylabel('% Change')
ax2.legend()

# Display the chart
plt.show()

# Load the test data
test_data = test_data

# Create the test environment
test_env = StockTradingEnv(test_data,initial_cash =100000)

# Define the number of Monte Carlo runs
monte_carlo_runs = 200
rewards = []

for run in tqdm(range(monte_carlo_runs)):
    # Test the agent
    state = test_env.reset()
    state = np.reshape(state, [1, state_size])
    total_reward = 0

    while True:
        action = agent.act(state)
        next_state, reward, done, _ = test_env.step(action)
        total_reward += reward
        next_state = np.reshape(next_state, [1, state_size])
        state = next_state

        if done:
            # print(f'Test Run: {run + 1}/{monte_carlo_runs}, Total Reward: {total_reward}')
            rewards.append(total_reward)
            break

# Calculate and print the average reward
average_reward = np.mean(rewards)
print(f'Average Reward after {monte_carlo_runs} runs: {average_reward}')

# getting more data
tickers = ["GOOG","IBM","AAPL","META","AMZN"]  #"^GSPC" S&P500
df = yf.download(tickers = tickers ,       # list of tickers
                  period = "2y",         # time period
                  interval = "1h",       # trading interval
                  ignore_tz = True,      # ignore timezone when aligning data from different exchanges?
                  prepost = False)       # download pre/post market hours data?
print("shape of dataset: ", df.shape)
df.head()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

split_line = int(np.round(len(df) * 0.1))  # use 10% of data for testing

# Get min and max of 'Adj Close'
adj_close_min = df['Close'].min().min()
adj_close_max = df['Close'].max().max()

# Set the background color
sns.set_style(rc={'axes.facecolor': 'lightsteelblue'})
plt.figure(figsize=(12, 4))

# Loop through each stock in the 'Adj Close' column and plot
for stock in df['Close'].columns:
    sns.lineplot(data=df['Close'][stock], label=f'Adjusted Close Price - {stock}')


plt.xticks(rotation=45)
plt.title(', '.join(df['Close'].columns))

# single vline with full ymin and ymax
plt.vlines(x=df.index[-split_line], ymin=adj_close_min, ymax=adj_close_max, colors='green', ls=':', lw=2, label='Train-Test Split Point')

plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')
plt.show()

# import gym
# import yfinance as yf
# import ta   # ta documentation: https://technical-analysis-library-in-python.readthedocs.io/en/latest/
# from tqdm import tqdm
# import numpy as np
# import pandas as pd
# from itertools import accumulate
# import matplotlib.pyplot as plt
# import seaborn as sns


# def add_indicators(df):

#     # Ensure the input DataFrame has 'Close' and 'Volume' columns
#     if 'Close' not in df.columns or 'Volume' not in df.columns:
#         raise ValueError("Input DataFrame must contain 'Close' and 'Volume' columns")

#     # Ensure 'Close' and 'Volume' are 1-dimensional Series explicitly
#     # Use .values.ravel() to flatten to a 1D numpy array, then convert to Series
#     close_values = df['Close'].values.ravel()
#     volume_values = df['Volume'].values.ravel()

#     # Create pandas Series with the original index
#     close_series = pd.Series(close_values, index=df.index)
#     volume_series = pd.Series(volume_values, index=df.index)

#     df['EMA7'] = ta.trend.EMAIndicator(close= close_series, window= 7, fillna= False).ema_indicator()
#     df['EMA14'] = ta.trend.EMAIndicator(close= close_series, window= 14, fillna= False).ema_indicator()
#     df['EMA50'] = ta.trend.EMAIndicator(close= close_series, window= 50, fillna= False).ema_indicator()
#     df['EMA200'] = ta.trend.EMAIndicator(close= close_series, window= 50, fillna= False).ema_indicator()
#     df['MACD_line'] =ta.trend.MACD(close= close_series, window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd()
#     df['MACD_signal'] =ta.trend.MACD(close= close_series, window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd_signal()
#     df['MACD_diff'] =ta.trend.MACD(close= close_series, window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd_diff()
#     df['RSI']=ta.momentum.RSIIndicator(close= close_series, window= 14, fillna= False).rsi()
#     df['OBV']= ta.volume.OnBalanceVolumeIndicator(close= close_series, volume= df['Volume'], fillna = False).on_balance_volume()
#     df['BBH']=ta.volatility.BollingerBands(close= close_series, window = 20, window_dev = 2, fillna = False).bollinger_hband_indicator()
#     df['BBL']=ta.volatility.BollingerBands(close= close_series, window = 20, window_dev = 2, fillna = False).bollinger_lband_indicator()
#     df=df.dropna()
#     df = df.drop(columns=['Open', 'High', 'Low', 'Volume'],axis=1)

#     return df



# ipython-input-50-f38f81b5e3e2
import gym
import yfinance as yf
import ta   # ta documentation: https://technical-analysis-library-in-python.readthedocs.io/en/latest/
from tqdm import tqdm
import numpy as np
import pandas as pd
from itertools import accumulate
import matplotlib.pyplot as plt
import seaborn as sns


def add_indicators(df):
    # Ensure the input DataFrame has 'Close' and 'Volume' columns
    if 'Close' not in df.columns or 'Volume' not in df.columns:
        raise ValueError("Input DataFrame must contain 'Close' and 'Volume' columns")

    # Ensure 'Close' and 'Volume' are 1-dimensional Series explicitly
    # Use .values.ravel() to flatten to a 1D numpy array, then convert to Series
    close_values = df['Close'].values.ravel()
    volume_values = df['Volume'].values.ravel()

    # Create pandas Series with the original index
    close_series = pd.Series(close_values, index=df.index)
    volume_series = pd.Series(volume_values, index=df.index)


    # Calculate technical indicators using the explicit 1D Series
    df['EMA7'] = ta.trend.EMAIndicator(close= close_series, window= 7, fillna= False).ema_indicator()
    df['EMA14'] = ta.trend.EMAIndicator(close= close_series, window= 14, fillna= False).ema_indicator()
    df['EMA50'] = ta.trend.EMAIndicator(close= close_series, window= 50, fillna= False).ema_indicator()
    df['EMA200'] = ta.trend.EMAIndicator(close= close_series, window= 200, fillna= False).ema_indicator() # Corrected window size
    df['MACD_line'] =ta.trend.MACD(close= close_series, window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd()
    df['MACD_signal'] =ta.trend.MACD(close= close_series, window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd_signal()
    df['MACD_diff'] =ta.trend.MACD(close= close_series, window_slow= 26, window_fast= 12, window_sign = 9, fillna = False).macd_diff()
    df['RSI']=ta.momentum.RSIIndicator(close= close_series, window= 14, fillna= False).rsi()
    # Pass the explicit volume_series to OBV
    df['OBV']= ta.volume.OnBalanceVolumeIndicator(close= close_series, volume= volume_series, fillna = False).on_balance_volume()
    df['BBH']=ta.volatility.BollingerBands(close= close_series, window = 20, window_dev = 2, fillna = False).bollinger_hband_indicator()
    df['BBL']=ta.volatility.BollingerBands(close= close_series, window = 20, window_dev = 2, fillna = False).bollinger_lband_indicator()

    # Drop rows with NaN values introduced by indicators
    df=df.dropna()

    # Drop original columns that are no longer needed (handle potential missing columns gracefully)
    columns_to_drop = ['Open', 'High', 'Low', 'Volume']
    df = df.drop(columns=columns_to_drop, axis=1, errors='ignore')

    return df

# loading individual stock data for every stock and calling add_indicator

df_GOOG = yf.download(tickers = 'GOOG' ,period = "2y", interval = "1h",ignore_tz = True,prepost = False)
df_GOOG = add_indicators(df_GOOG)

df_IBM = yf.download(tickers = 'IBM' ,period = "2y", interval = "1h",ignore_tz = True,prepost = False)
df_IBM = add_indicators(df_IBM)

df_AAPL = yf.download(tickers = 'AAPL' ,period = "2y", interval = "1h",ignore_tz = True,prepost = False)
df_AAPL = add_indicators(df_AAPL)

df_META = yf.download(tickers = 'META' ,period = "2y", interval = "1h",ignore_tz = True,prepost = False)
df_META = add_indicators(df_META)

df_AMZN = yf.download(tickers = 'AMZN' ,period = "2y", interval = "1h",ignore_tz = True,prepost = False)
df_AMZN = add_indicators(df_AMZN)


# Re-calculate split_line based on the processed dataframes if it wasn't done globally already
# For consistency, let's assume split_line should be based on the length of each individual stock df
split_line = int(np.round(len(df_GOOG) * 0.1)) # Assuming all processed dataframes have similar lengths after dropna


train_data1 = df_GOOG.iloc[:-split_line,:]
train_data2 = df_IBM.iloc[:-split_line,:]
train_data3 = df_AAPL.iloc[:-split_line,:]
train_data4 = df_META.iloc[:-split_line,:]
train_data5 = df_AMZN.iloc[:-split_line,:]

train_df_list = [train_data1,train_data2,train_data3,train_data4,train_data5]

import yfinance as yf

tickers = ['GOOG', 'IBM', 'AAPL', 'META', 'AMZN']
train_df_list = []

for ticker in tickers:
    df = yf.download(tickers=ticker, period="2y", interval="1h", ignore_tz=True, prepost=False)
    df = add_indicators(df)
    train_data = df.iloc[:-split_line, :]
    train_df_list.append(train_data)

'''
training loop to handle multiple dataframes like df_1, df_2, df_3, you can create a list of dataframes and loop through them.
'''
# Load the stock dataframes
data_list = train_df_list

# Create and train the agent
agent = DQNAgent(state_size, env.action_space, memory_size=4000) # increasing the memory size for the agent
episodes = 10
batch_size = 32

for data in data_list:
    env = StockTradingEnv(data)
    state_size = env.observation_space.shape[0]
    action_size = env.action_space.nvec.prod()

    for e in tqdm(range(episodes)):
        state = env.reset()
        state = np.reshape(state, [1, state_size])
        total_reward = 0

        while True:
            action = agent.act(state)
            next_state, reward, done, _ = env.step(action)
            total_reward += reward
            next_state = np.reshape(next_state, [1, state_size])

            agent.remember(state, action, reward, next_state, done)
            state = next_state

            if done:
                # print(f'Episode: {e + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.2}')
                break

        if len(agent.memory) > batch_size:
            agent.replay(batch_size)

# using Apple data for testing
test_data = df_AAPL.iloc[-split_line:,:]



# Create the test environment
test_env = StockTradingEnv(test_data,initial_cash =10000)

# Define the number of Monte Carlo runs
monte_carlo_runs = 200
rewards = []

for run in tqdm(range(monte_carlo_runs)):
    # Test the agent
    state = test_env.reset()
    state = np.reshape(state, [1, state_size])
    total_reward = 0

    while True:
        action = agent.act(state)
        next_state, reward, done, _ = test_env.step(action)
        total_reward += reward
        next_state = np.reshape(next_state, [1, state_size])
        state = next_state

        if done:
            # print(f'Test Run: {run + 1}/{monte_carlo_runs}, Total Reward: {total_reward}')
            rewards.append(total_reward)
            break

# Calculate and print the average reward
average_reward = np.mean(rewards)
print(f'Average Reward after {monte_carlo_runs} runs: {average_reward}')